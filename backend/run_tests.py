#!/usr/bin/env python
"""
Script pour ex√©cuter les tests avec diff√©rentes configurations
"""
import argparse
import re
import subprocess
import sys


def parse_pytest_output(output):
    """Parse la sortie de pytest pour extraire les statistiques"""
    stats = {"passed": 0, "failed": 0, "skipped": 0, "errors": 0, "total": 0}

    # Chercher la ligne de r√©sum√© (ex: "23 passed, 48 skipped, 2 failed in 12.34s")
    summary_pattern = r"(\d+)\s+passed|(\d+)\s+failed|(\d+)\s+skipped|(\d+)\s+error"

    for match in re.finditer(summary_pattern, output):
        if match.group(1):  # passed
            stats["passed"] = int(match.group(1))
        elif match.group(2):  # failed
            stats["failed"] = int(match.group(2))
        elif match.group(3):  # skipped
            stats["skipped"] = int(match.group(3))
        elif match.group(4):  # errors
            stats["errors"] = int(match.group(4))

    stats["total"] = stats["passed"] + stats["failed"] + stats["skipped"] + stats["errors"]

    return stats


def run_command(command, description):
    """Ex√©cute une commande et affiche le r√©sultat"""
    print(f"\n{'='*60}")
    print(f"üß™ {description}")
    print(f"{'='*60}\n")

    # Ex√©cute la commande en capturant la sortie tout en l'affichant
    process = subprocess.Popen(
        command,
        shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
    )

    output_lines = []
    for line in process.stdout:
        print(line, end="")
        output_lines.append(line)

    process.wait()
    output = "".join(output_lines)

    return process.returncode == 0, output


def build_base_command(args):
    """Construit la commande pytest de base en fonction des options."""
    base_command = "python -m pytest"

    if args.verbose:
        base_command += " -v"

    if args.parallel:
        base_command += f" -n {args.parallel}"

    if args.coverage:
        base_command += " --cov=apps --cov-report=html --cov-report=term-missing"

    # Filtres de tests
    test_filters = []

    if args.unit:
        test_filters.append("-m unit")
    elif args.integration:
        test_filters.append("-m integration")
    elif args.celery:
        test_filters.append("-m celery")

    if args.app:
        test_filters.append(f"apps/{args.app}/tests/")

    if test_filters:
        base_command += " " + " ".join(test_filters)

    return base_command


def print_intro():
    """Affiche l'en-t√™te de la suite de tests."""
    print("\n" + "=" * 60)
    print("üß™ LUDOKAN - SUITE DE TESTS")
    print("=" * 60)
    print("\n‚ö†Ô∏è  Note: Les tests des mod√®les non impl√©ment√©s seront skipped")
    print("üìã V√©rifiez le r√©sum√© √† la fin pour voir le nombre de tests skip\n")


def print_summary(stats):
    """Affiche le r√©sum√© des r√©sultats de tests."""
    print("\n" + "=" * 60)
    print("üìä R√âSUM√â DES TESTS")
    print("=" * 60)
    print(f"‚úÖ Tests r√©ussis (PASSED) : {stats['passed']}")
    if stats["failed"] > 0:
        print(f"‚ùå Tests √©chou√©s (FAILED) : {stats['failed']} - Assertions non satisfaites")
    else:
        print(f"‚ùå Tests √©chou√©s (FAILED) : {stats['failed']}")

    if stats["errors"] > 0:
        print(f"üí• Erreurs (ERROR)        : {stats['errors']} - Erreurs d'ex√©cution/setup")

    print(f"‚ö†Ô∏è  Tests skipp√©s (SKIPPED) : {stats['skipped']}")
    print(f"üìà Total : {stats['total']} tests")
    print("=" * 60)

    if stats["skipped"] > 0:
        print(f"\nüí° {stats['skipped']} test(s) ont √©t√© skipp√©s")
        print("   (Fonctionnalit√©s non encore impl√©ment√©es ou tests Celery d√©sactiv√©s)")


def handle_exit(success, stats, coverage_enabled):
    """G√®re la logique de sortie (code retour + messages compl√©mentaires)."""
    if success and stats["failed"] == 0 and stats["errors"] == 0:
        print("\n‚úÖ Tous les tests actifs passent!")
        if coverage_enabled:
            print("üìä Rapport de couverture g√©n√©r√© dans htmlcov/index.html")
        sys.exit(0)

        total_issues = stats["failed"] + stats["errors"]
        print(f"\n‚ùå {total_issues} probl√®me(s) d√©tect√©(s):")
        if stats["failed"] > 0:
            print(f"   ‚Ä¢ {stats['failed']} test(s) FAILED (assertions √©chou√©es)")
        if stats["errors"] > 0:
            print(f"   ‚Ä¢ {stats['errors']} ERROR(s) (probl√®mes d'ex√©cution/setup)")
        print("\n   üìã Consultez la sortie ci-dessus pour plus de d√©tails")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="Ex√©cuter les tests LudoKan")
    parser.add_argument("--unit", action="store_true", help="Ex√©cuter seulement les tests unitaires")
    parser.add_argument(
        "--integration",
        action="store_true",
        help="Ex√©cuter seulement les tests d'int√©gration",
    )
    parser.add_argument("--celery", action="store_true", help="Ex√©cuter seulement les tests Celery")
    parser.add_argument("--coverage", action="store_true", help="G√©n√©rer un rapport de couverture")
    parser.add_argument("--verbose", "-v", action="store_true", help="Mode verbeux")
    parser.add_argument("--parallel", "-n", type=int, help="Ex√©cuter les tests en parall√®le")
    parser.add_argument("--app", help="Ex√©cuter les tests d'une app sp√©cifique")

    args = parser.parse_args()

    print_intro()
    base_command = build_base_command(args)

    # Ex√©cution des tests
    success, output = run_command(base_command, "Ex√©cution des tests")

    # Parser les r√©sultats
    stats = parse_pytest_output(output)

    # Affichage du r√©sum√© final
    print_summary(stats)

    # G√©rer le code de retour et les messages finaux
    handle_exit(success, stats, args.coverage)


if __name__ == "__main__":
    main()
