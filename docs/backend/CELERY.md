# Configuration Celery pour LudoKan

## üöÄ D√©marrage rapide

### 1. D√©marrer tous les services
```bash
docker compose up -d
```

### 2. V√©rifier que Celery fonctionne
```bash
# Voir les logs du worker
docker compose logs celery

# Voir les logs du scheduler
docker compose logs celery-beat

# Tester les t√¢ches
docker compose exec web python test_celery.py
```

## üìã Services disponibles

- **web**: Application Django (port 8000)
- **db**: PostgreSQL (port 5432)
- **redis**: Redis (port 6379)
- **celery**: Worker Celery pour les t√¢ches asynchrones
- **celery-beat**: Scheduler pour les t√¢ches p√©riodiques

## üîß Commandes utiles

### Gestion des services
```bash
# D√©marrer seulement Celery
docker compose up celery celery-beat

# Red√©marrer Celery
docker compose restart celery celery-beat

# Voir les logs en temps r√©el
docker compose logs -f celery
```

### Monitoring Celery
```bash
# Acc√©der au shell Django
docker compose exec web python manage.py shell

# Dans le shell Python:
from apps.core.tasks import send_welcome_email
result = send_welcome_email.delay("test@example.com", "TestUser")
print(result.get())
```

### Commandes Celery directes
```bash
# Worker avec plus de verbosit√©
docker compose exec web celery -A config worker -l debug

# Beat scheduler
docker compose exec web celery -A config beat -l info

# Voir les t√¢ches en attente
docker compose exec web celery -A config inspect active

# Purger toutes les t√¢ches
docker compose exec web celery -A config purge
```

## üìù Exemples de t√¢ches

### T√¢che simple
```python
from celery import shared_task

@shared_task
def ma_tache(param1, param2):
    # Votre logique ici
    return f"Traitement termin√©: {param1} + {param2}"
```

### T√¢che avec retry
```python
from celery import shared_task
from celery.exceptions import Retry

@shared_task(bind=True, max_retries=3)
def tache_avec_retry(self, data):
    try:
        # Votre logique ici
        return "Succ√®s"
    except Exception as exc:
        # Retry apr√®s 60 secondes
        raise self.retry(exc=exc, countdown=60)
```

### T√¢che p√©riodique
Dans `config/celery.py`, ajoutez √† `beat_schedule`:
```python
app.conf.beat_schedule = {
    'nettoyage-quotidien': {
        'task': 'apps.core.tasks.cleanup_old_sessions',
        'schedule': crontab(hour=2, minute=0),  # Tous les jours √† 2h
    },
}
```

## üêõ D√©pannage

### Probl√®me: Worker ne d√©marre pas
```bash
# V√©rifier les logs
docker compose logs celery

# V√©rifier la configuration
docker compose exec web python -c "from config.celery import app; print(app.conf.broker_url)"
```

### Probl√®me: T√¢ches ne s'ex√©cutent pas
```bash
# V√©rifier la connexion Redis
docker compose exec redis redis-cli ping

# V√©rifier les t√¢ches en attente
docker compose exec web celery -A config inspect active
```

### Probl√®me: Beat ne fonctionne pas
```bash
# V√©rifier les logs
docker compose logs celery-beat

# Red√©marrer beat
docker compose restart celery-beat
```

## üìä Monitoring avanc√©

### Flower (interface web pour Celery)
Ajoutez √† `requirements.txt`:
```
flower==2.0.1
```

Ajoutez au `docker-compose.yml`:
```yaml
flower:
  build: 
    context: backend
    dockerfile: Dockerfile
  command: celery -A config flower
  ports:
    - "5555:5555"
  env_file:
    - .env
  depends_on:
    - redis
```

Acc√©dez √† http://localhost:5555 pour le monitoring.
